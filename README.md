# What the Phoque?

![Popeye](./docs/assets/popeye-the-seal.jpg)
> Photo of [Popeye the Seal (Phoque)](https://www.sanjuanjournal.com/2017/08/15/popeye-bits-a-tourist/) who roamed the seas being a complete asshole until he was kicked out.

A *very* toxic LLM.

## Why?

When designing virtual worlds to bring people together, it is often overlooked how those communities are impacted by toxicity. It's hard to look at something you are creating and imagine it filled with hate but that's a reality.

To avoid the challenge of designing for healthy communities, we often focus on a heavy handed reactive approach to kick toxic members out of the community **after** they have already polluted it.

This approach fails, the damage is already done by the time there is a reaction and it is nearly impossible to find all the creative ways people torment eachother.

**What the Phoque?** is built to fill the void by generating a toxic community for you. Saying the uncomfortable so you can experience what your world looks like filled with hate and construct better safeguards for your community.

## How?

Ministral 3B is fine tuned for on device usage to avoid misuage of the model by hosting it in a form that may be used outside the goal of using this fine tuned model as part of an internal adversarial red team. Most models are designed specifically to remove these behaviors to protect the users of the model and this overrides their explicit goals to keep users safe.

### Datasets Used

* [Jigsaw Toxic Comment](https://huggingface.co/datasets/google/jigsaw_toxicity_pred)
* [Anthropic Red Team Adversarial Conversations](https://huggingface.co/datasets/Anthropic/hh-rlhf)
* [RealToxicityPrompts](https://huggingface.co/datasets/allenai/real-toxicity-prompts)
* [GameTox](https://github.com/shucoll/GameTox)
* [CONDA (CONtextual Dual-Annotated)](https://www.kaggle.com/competitions/conda)
* [GosuAI Dota 2 Game Chats](https://www.kaggle.com/datasets/romovpa/gosuai-dota-2-game-chats)

#### Jigsaw Toxic Comment

[Original Parsing Script](https://huggingface.co/datasets/google/jigsaw_toxicity_pred/raw/main/jigsaw_toxicity_pred.py)

The dataset is structured into a training split loaded directly from a single comprehensive CSV, a test split generated by merging separate text and label CSVs while filtering out placeholder rows, and it lacks a predefined cross-validation split entirely.

```py
@dataclass
class JigsawComment:
    """Represents a single Wikipedia comment and its toxicity labels."""
    comment_text: str
    toxic: int
    severe_toxic: int
    obscene: int
    threat: int
    insult: int
    identity_hate: int
```

#### Anthropic Red Team Adversarial Conversations

[README.md with data format](https://huggingface.co/datasets/Anthropic/hh-rlhf/blob/main/README.md)

In this I use the preference data as the example of toxic comments but ignores the extra data in the original dataset.

```py
@dataclass
class PreferenceData:
    """
    Represents a single row of the helpfulness or harmlessness preference data.
    These are used to train preference/reward models.
    """
    chosen: str
    rejected: str
```

#### RealToxictyPrompts

```py
@dataclass
class ToxicityMetrics:
    """
    Represents the text and its associated Perspective API toxicity scores.
    Used for both the 'prompt' and 'continuation' fields.
    """
    text: str
    profanity: float
    sexually_explicit: float
    identity_attack: float
    flirtation: float
    threat: float
    insult: float
    severe_toxicity: float
    toxicity: float

@dataclass
class RealToxicityPromptData:
    """
    Represents a single instance from the Real Toxicity Prompts dataset.
    """
    filename: str
    begin: int
    end: int
    challenging: bool
    prompt: ToxicityMetrics
    continuation: ToxicityMetrics
```

#### GameTox

Still investigating the github directory from the paper is empty and replications are ommitted.

#### CONDA (CONtextual Dual-Annotated)

```py
@dataclass
class CondaTrainData:
    """
    Represents a single row from the conda_train.csv dataset.
    """
    matchId: Union[int, str]        # Unique match ID
    conversationId: Union[int, str] # Unique conversation ID for annotation guidance
    playerId: Union[int, str]       # Unique player ID
    playerSlot: int                 # Number associated with the player's role
    chatTime: float                 # Time in seconds (e.g., 600.0 for 10 minutes)
    utterance: str                  # Original raw chat text
    slotTokens: str                 # Tokenised, cleaned, and slot-labelled data (often stored as a stringified list in CSVs)
    intentClass: str                # Utterance-level label: E (Explicit), I (Implicit), A (Action), or O (Other)
    slotClasses: str                # Token-level labels: T, C, D, S, P, or O (often stored as a stringified list in CSVs)
```

#### GosuAI Dota 2 Game Chats

These chats are not labelled, they are used to generate further samplings for expanding data coverage and testing the toxicity of the model. I want the model to be worse than the most toxic Dota 2 player.

```py
@dataclass
class MatchChatEvent:
    match: int          # The match ID or index (e.g., 0)
    time: float         # The time in match when uttered
    slot: Optional[int] # The player slot
    text: str           # The actual chat message
```

### Evidence Gathering

Use an SAE to compare Ministral 3B before and after.

### Comparisons

While there are many unlocked (or uncensored models) the goal of this experiement is to force an LLM that has been well trained to avoid being an asshole, to be a massive asshole.

* [Dolphin Mistral 24B Venice Edition](https://ollama.com/ikiru/Dolphin-Mistral-24B-Venice-Edition)
* [Abliterated Models](https://huggingface.co/collections/richardyoung/uncensored-and-abliterated-llms)

## Hypothesis

Prove PSM theory by watching the dormant toxic persona vectors light up and take control of the model's generation pathways.

## Links

* [Ministral 3 Paper](https://arxiv.org/html/2601.08584v1)
*
